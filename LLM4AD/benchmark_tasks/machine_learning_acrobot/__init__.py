#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Autonomous LLM4AD task: machine_learning_acrobot
Generated by convert_llm4ad_benchmark.py

This is a fully self-contained task module that doesn't depend on the original LLM4AD codebase.
"""

# Embedded evaluation code (benchmark)
# Module Name: AcrobotEvaluation
# Last Revision: 2025/3/5
# Description: Designs a heuristic strategy function for controlling an acrobot system.
#              The function selects actions based on joint angles and angular velocities
#              to efficiently swing the lower link and generate momentum for the upper
#              link to reach the target height.
#              This module is part of the LLM4AD project (https://github.com/Optima-CityU/llm4ad).
#
# Parameters:
#    -   cos_theta1: float - cosine of theta1, range [-1, 1] (default: None).
#    -   sin_theta1: float - sine of theta1, range [-1, 1] (default: None).
#    -   cos_theta2: float - cosine of theta2, range [-1, 1] (default: None).
#    -   sin_theta2: float - sine of theta2, range [-1, 1] (default: None).
#    -   a_v_theta1: float - angular velocity of theta1, range [-12.567, 12.567] (default: None).
#    -   a_v_theta2: float - angular velocity of theta2, range [-28.274, 28.274] (default: None).
#    -   last_action: int - last action taken, values [0, 1, 2] (default: None).
#    -   timeout_seconds: int - Maximum allowed time (in seconds) for the evaluation process (default: 20).
#
# References:
#   - Brockman, Greg, et al. "Openai gym." arXiv preprint arXiv:1606.01540 (2016).
#
# ------------------------------- Copyright --------------------------------
# Copyright (c) 2025 Optima Group.
#
# Permission is granted to use the LLM4AD platform for research purposes.
# All publications, software, or other works that utilize this platform
# or any part of its codebase must acknowledge the use of "LLM4AD" and
# cite the following reference:
#
# Fei Liu, Rui Zhang, Zhuoliang Xie, Rui Sun, Kai Li, Xi Lin, Zhenkun Wang,
# Zhichao Lu, and Qingfu Zhang, "LLM4AD: A Platform for Algorithm Design
# with Large Language Model," arXiv preprint arXiv:2412.17287 (2024).
#
# For inquiries regarding commercial use or licensing, please contact
# http://www.llm4ad.com/contact.html
# --------------------------------------------------------------------------



from __future__ import annotations

from typing import Any
import os, sys
sys.path.insert(0, os.path.dirname(__file__))
import gym

from llm4ad_loader import Evaluation
# from llm4ad.task.machine_learning.acrobot.template import template_program, task_description  # Template values embedded below

# Embedded template values
template_program = 'import numpy as np\n\ndef choose_action(ct1: float, st1: float, ct2: float, st2: float, avt1: float, avt2: float, last_action: int) -> int: \n    """\n    Design a novel algorithm to select the action in each step.\n\n    Args:\n        ct1: cosine of theta1, float between [-1, 1].\n        st1: sine of theta1, float between [-1, 1]\n        ct2: cosine of theta2, float between [-1, 1].\n        st2: sine of theta2, float between [-1, 1].\n        avt1: angular velocity of theta1, float between [-12.567, 12.567].\n        avt2: angular velocity of theta2, float between [-28.274, 28.274].\n\n\n    Return:\n         An integer representing the selected action for the acrobot.\n         0: apply -1 torque on actuated  joint.\n         1: apply 0 torque on actuated joint\n         2: apply +1 torque on actuated joint.\n\n    """\n    # this is a placehold, replace it with your algorithm\n    action =  np.random.randint(3)\n\n    return action'
task_description = '("I need help designing an innovative heuristic strategy function to control an acrobot, aiming to "'


__all__ = ['AcrobotEvaluation']


def evaluate(env: gym.Env, action_select: callable) -> float:
    """Evaluate heuristic function on car mountain problem."""

    observation, _ = env.reset()  # initialization
    action = 0  # initial action

    for i in range(env._max_episode_steps + 1):  # protect upper limits
        action = action_select(observation[0],
                               observation[1],
                               observation[2],
                               observation[3],
                               observation[4],
                               observation[5],
                               action)
        observation, reward, done, truncated, info = env.step(action)

        if done or truncated:
            # self.env.close()
            fitness = observation[0] + (observation[0] * observation[2] - observation[1] * observation[3]) + 2
            if fitness <= 1:
                return -(i + 1) / env._max_episode_steps
            else:
                return -fitness


class AcrobotEvaluation(Evaluation):
    """Evaluator for car mountain problem."""

    def __init__(self, max_steps=500, timeout_seconds=20, **kwargs):
        """
            Args:
                - 'max_steps' (int): Maximum number of steps allowed per episode in the MountainCar-v0 environment (default is 500).
                - '**kwargs' (dict): Additional keyword arguments passed to the parent class initializer.

            Attributes:
                - 'env' (gym.Env): The MountainCar-v0 environment with a modified maximum episode length.
        """

        super().__init__(
            template_program=template_program,
            task_description=task_description,
            use_numba_accelerate=False,
            timeout_seconds=timeout_seconds
        )

        self.env = None
        self.env = gym.make('Acrobot-v1')
        self.env._max_episode_steps = max_steps

    def evaluate_program(self, program_str: str, callable_func: callable) -> Any | None:
        return evaluate(self.env, callable_func)

# Task configuration for benchmark task
ENTRY_NAME = 'choose_action'
FUNCTION_SIGNATURE = 'def choose_action(...):'
IMPORT_HEADER = 'import numpy as np\nimport math'
TASK_DESCRIPTION = '("I need help designing an innovative heuristic strategy function to control an acrobot, aiming to "'
OBJECTIVE_TEXT = 'You are optimizing the implementation of `choose_action` for the LLM4AD task.\\n\\nTask description:\\n("I need help designing an innovative heuristic strategy function to control an acrobot, aiming to "\\n\\nYour goal is to return a correct and efficient function whose score (computed by the task evaluator) is as high as possible.'
TEMPLATE_FUNCTION = 'import numpy as np\n\ndef choose_action(ct1: float, st1: float, ct2: float, st2: float, avt1: float, avt2: float, last_action: int) -> int: \n    """\n    Design a novel algorithm to select the action in each step.\n\n    Args:\n        ct1: cosine of theta1, float between [-1, 1].\n        st1: sine of theta1, float between [-1, 1]\n        ct2: cosine of theta2, float between [-1, 1].\n        st2: sine of theta2, float between [-1, 1].\n        avt1: angular velocity of theta1, float between [-12.567, 12.567].\n        avt2: angular velocity of theta2, float between [-28.274, 28.274].\n\n\n    Return:\n         An integer representing the selected action for the acrobot.\n         0: apply -1 torque on actuated  joint.\n         1: apply 0 torque on actuated joint\n         2: apply +1 torque on actuated joint.\n\n    """\n    # this is a placehold, replace it with your algorithm\n    action =  np.random.randint(3)\n\n    return action'
EVAL_CLASS_NAME = 'AcrobotEvaluation'
EVAL_KWARGS = {'max_steps': 500, 'timeout_seconds': 20}

def build_trace_problem(**override_eval_kwargs) -> dict:
    """Build a Trace-ready problem using embedded benchmark evaluator."""
    
    # Create evaluator instance with embedded class
    eval_kwargs_final = EVAL_KWARGS.copy()
    eval_kwargs_final.update(override_eval_kwargs)
    
    evaluator = globals()[EVAL_CLASS_NAME](**eval_kwargs_final)
    
    from llm4ad_loader import AutonomousEvaluatorGuide
    from opto import trace
    
    # Create parameter
    initial_code = TEMPLATE_FUNCTION.strip()
    param = trace.node(initial_code, name='__code', 
                      description=f'The code should start with: {FUNCTION_SIGNATURE}', 
                      trainable=True)
    
    # Create guide using benchmark embedded evaluator
    guide = AutonomousEvaluatorGuide(evaluator, ENTRY_NAME, IMPORT_HEADER, 
                                   timeout=eval_kwargs_final.get('timeout_seconds', 30))
    
    # Create dataset
    train_dataset = dict(
        inputs=[TASK_DESCRIPTION],
        infos=[{'imports': IMPORT_HEADER, 'entry': ENTRY_NAME}]
    )
    
    # Optimizer kwargs
    optimizer_kwargs = dict(
        objective=OBJECTIVE_TEXT,
        memory_size=10
    )
    
    return dict(
        param=param,
        guide=guide,
        train_dataset=train_dataset,
        optimizer_kwargs=optimizer_kwargs,
        metadata=dict(
            entry=ENTRY_NAME,
            function_signature=FUNCTION_SIGNATURE,
            eval_class=EVAL_CLASS_NAME,
            benchmark=True,
        )
    )
