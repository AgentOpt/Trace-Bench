#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Autonomous LLM4AD task: optimization_open_shop_scheduling
Generated by convert_llm4ad_benchmark.py

This is a fully self-contained task module that doesn't depend on the original LLM4AD codebase.
"""

# Embedded evaluation code (benchmark)
# References:
#   - Sun, W., Feng, S., Li, S., & Yang, Y. Co-bench: Benchmarking language
#       model agents in algorithm search for combinatorial optimization.
#       arXiv preprint arXiv:2504.04310 (2025).
#
# ------------------------------- Copyright --------------------------------
# Copyright (c) 2025 Optima Group.
#
# Permission is granted to use the LLM4AD platform for research purposes.
# All publications, software, or other works that utilize this platform
# or any part of its codebase must acknowledge the use of "LLM4AD" and
# cite the following reference:
#
# Fei Liu, Rui Zhang, Zhuoliang Xie, Rui Sun, Kai Li, Xi Lin, Zhenkun Wang,
# Zhichao Lu, and Qingfu Zhang, "LLM4AD: A Platform for Algorithm Design
# with Large Language Model," arXiv preprint arXiv:2412.17287 (2024).
#
# For inquiries regarding commercial use or licensing, please contact
# http://www.llm4ad.com/contact.html
# --------------------------------------------------------------------------

from __future__ import annotations

from typing import Any
import numpy as np
from llm4ad_loader import Evaluation
from llm4ad_loader import load_subdir_as_text
# from llm4ad.task.optimization.co_bench.utils import load_subdir_as_text  # Common utilities from llm4ad_loader
# from llm4ad.task.optimization.co_bench.open_shop_scheduling_co_bench.template import template_program, task_description  # Template values embedded below

# Embedded template values
template_program = 'import numpy as np\nimport scipy.optimize as opt\nimport math\nimport random\nfrom typing import List, Tuple, Dict\ndef solve(n_jobs: int, n_machines: int, times: list, machines: list) -> dict:\n    """\n    Solves a single open shop scheduling test case.\n    Input kwargs:\n        - n_jobs (int): Number of jobs.\n        - n_machines (int): Number of machines (and operations per job).\n        - times (list of list of int): A 2D list of processing times for each operation.\n          Dimensions: n_jobs x n_machines.\n        - machines (list of list of int): A 2D list specifying the machine assignment for each operation.\n          Dimensions: n_jobs x n_machines. Note machine is 1-indexed.\n    Output:\n        solution (dict): A dictionary containing:\n            - start_times (list of list of int): A 2D list of start times for each operation.\n              Dimensions: n_jobs x n_machines.\n            Each start time must be a non-negative integer, and the schedule must respect the following constraint:\n                (i) Non-parallel operation: Each job must be processed on only one machine at a time\n                (ii) Machine exclusivity: For operations assigned to the same machine, their processing intervals must not overlap.\n            The evaluation function will use the start_times to compute the makespan and verify the constraints.\n    """\n\n    # Extract the case parameters\n    n_jobs = kwargs["n_jobs"]\n    n_machines = kwargs["n_machines"]\n    times = kwargs["times"]\n    machines = kwargs["machines"]\n\n    # TODO: Implement the scheduling algorithm here.\n    # For now, we provide a dummy solution where all operations start at time 0.\n\n    # Create a start_times list with dimensions n_jobs x n_machines, initializing all start times to 0.\n    start_times = [[0 for _ in range(n_machines)] for _ in range(n_jobs)]\n\n    # Build the solution dictionary.\n    solution = {"start_times": start_times}\n\n    return solution'
task_description = '("The Open Shop Scheduling Problem involves scheduling a set of jobs across a set of machines with "'


__all__ = ['OSSEvaluationCB']


class OSSEvaluationCB(Evaluation):

    def __init__(self,
                 timeout_seconds=50,
                 **kwargs):

        """
            Args:
                None
            Raises:
                AttributeError: If the data key does not exist.
                FileNotFoundError: If the specified data file is not found.
        """

        super().__init__(
            template_program=template_program,
            task_description=task_description,
            use_numba_accelerate=False,
            timeout_seconds=timeout_seconds
        )

        # Load datasets from Hugging Face
        dataset = load_subdir_as_text("CO-Bench/CO-Bench", "Open shop scheduling")
        self._datasets = {}
        for filename in dataset:
            # Join all text rows into a single string
            text_content = '\n'.join([row['text'] for row in dataset[filename]])
            self._datasets[filename] = text_content

    def evaluate_program(self, program_str: str, callable_func: callable, **kwargs) -> Any | None:
        return self.evaluate(callable_func)

    def evaluate(self, eva: callable) -> float | None:
        ins_cases = []
        for case_id, ins in enumerate(self._datasets.values()):
            ins_cases.append(self.load_data(ins))

        fitness_list = []
        try:
            for i in ins_cases:
                for j in i:
                    result = eva(j['n_jobs'], j['n_machines'], j['times'], j['machines'])
                    fitness = self.eval_func(j['n_jobs'], j['n_machines'], j['times'], j['machines'], result['start_times'], lower_bound=j['lower_bound'], upper_bound=j['upper_bound'])
                    fitness_list.append(fitness)

            return -np.mean(fitness_list)

        except ValueError as e:
            print(e)
            return None

    def load_data(self, input_string):
        cases = []
        lines = [line.strip() for line in input_string.split('\n') if line.strip()]  # remove blank lines

        i = 0
        while i < len(lines):
            # Look for a header line starting with "Nb of jobs"
            if lines[i].startswith("number of jobs"):
                # Next line contains six numbers: n_jobs, n_machines, time_seed, machine_seed, upper_bound, lower_bound
                i += 1
                header_tokens = lines[i].split()
                if len(header_tokens) < 6:
                    raise ValueError("Header line does not contain 6 values.")
                n_jobs = int(header_tokens[0])
                n_machines = int(header_tokens[1])
                time_seed = int(header_tokens[2])
                machine_seed = int(header_tokens[3])
                upper_bound = int(header_tokens[4])
                lower_bound = int(header_tokens[5])

                # Find the "Times" section
                i += 1
                if not lines[i].lower().startswith("processing"):
                    raise ValueError("Expected 'Times' section, got: " + lines[i])
                i += 1  # move to first line of times
                times = []
                for _ in range(n_jobs):
                    # Each line should contain n_machines numbers
                    time_line = list(map(int, lines[i].split()))
                    if len(time_line) != n_machines:
                        raise ValueError(f"Expected {n_machines} numbers in times row, got {len(time_line)}")
                    times.append(time_line)
                    i += 1

                # Find the "Machines" section
                if i >= len(lines) or not lines[i].lower().startswith("machines"):
                    raise ValueError("Expected 'Machines' section, got: " + (lines[i] if i < len(lines) else "EOF"))
                i += 1  # move to first line of machines
                machines = []
                for _ in range(n_jobs):
                    machine_line = list(map(int, lines[i].split()))
                    if len(machine_line) != n_machines:
                        raise ValueError(f"Expected {n_machines} numbers in machines row, got {len(machine_line)}")
                    machines.append(machine_line)
                    i += 1

                # Build the test case dictionary and add to the list of cases.
                case = {
                    "n_jobs": n_jobs,
                    "n_machines": n_machines,
                    "time_seed": time_seed,
                    "machine_seed": machine_seed,
                    "upper_bound": upper_bound,
                    "lower_bound": lower_bound,
                    "times": times,
                    "machines": machines
                }
                cases.append(case)
            else:
                # If the current line is not a header, skip it.
                i += 1

        return cases

    def eval_func(self, n_jobs, n_machines, times, machines, start_times, **kwargs):
        """
        Evaluates the solution for a open shop scheduling problem.
        Input:
            n_jobs (int): Number of jobs.
            n_machines (int): Number of machines.
            times (list of list of int): Processing times for each operation.
                Dimensions: n_jobs x n_machines.
            machines (list of list of int): Machine assignments for each operation.
                Dimensions: n_jobs x n_machines.
            start_times (list of list of int): Proposed start times for each operation.
                Dimensions: n_jobs x n_machines.
            kwargs: Other parameters that may be provided, which are ignored here.
        Output:
            score (int): The makespan, defined as the maximum completion time across all jobs.
        Raises:
            ValueError: If any scheduling constraints are violated.
        """

        # Check that start_times dimensions match the problem dimensions.
        if len(start_times) != n_jobs:
            raise ValueError(f"Expected start_times to have {n_jobs} rows, got {len(start_times)}")
        for i, row in enumerate(start_times):
            if len(row) != n_machines:
                raise ValueError(f"Expected start_times row {i} to have {n_machines} entries, got {len(row)}")
            for t in row:
                if t < 0:
                    raise ValueError("Start times must be non-negative.")

        job_operations = []
        job_completion_times = []
        for i in range(n_jobs):
            job_operations.append([])
            finish_time = 0
            for j in range(n_machines):
                st = start_times[i][j]
                pt = times[i][j]
                finish_time = max(finish_time, st + pt)
                job_operations[i].append((st, st + pt))
            job_completion_times.append(finish_time)

        for job_id in range(n_jobs):
            ops = sorted(job_operations[job_id], key=lambda x: x[0])  # Sort by start time
            for i in range(len(ops) - 1):
                if ops[i][1] > ops[i + 1][0]:  # End time of current > start time of next
                    raise ValueError(f"Overlapping operations for job {job_id}: {ops[i]} and {ops[i + 1]}")

        # Constraint: Machine non-overlap.
        # Build a dictionary mapping machine id to a list of (start_time, finish_time, job, op_index)
        machine_schedules = {}
        for i in range(n_jobs):
            for j in range(n_machines):
                machine_id = machines[i][j]
                st = start_times[i][j]
                pt = times[i][j]
                finish_time = st + pt
                if machine_id not in machine_schedules:
                    machine_schedules[machine_id] = []
                machine_schedules[machine_id].append((st, finish_time, i, j))

        # For each machine, sort operations by start time and check for overlaps.
        for machine_id, ops in machine_schedules.items():
            ops_sorted = sorted(ops, key=lambda x: x[0])
            for k in range(1, len(ops_sorted)):
                prev_st, prev_finish, prev_job, prev_op = ops_sorted[k - 1]
                curr_st, curr_finish, curr_job, curr_op = ops_sorted[k]
                if prev_finish > curr_st:
                    raise ValueError(
                        f"Machine {machine_id}: Operation from job {prev_job}, op {prev_op} (finishing at {prev_finish}) overlaps with job {curr_job}, op {curr_op} (starting at {curr_st}).")

        # Compute the makespan as the maximum completion time among all jobs.
        makespan = max(job_completion_times)

        score = kwargs['lower_bound'] / makespan

        return score

    def get_dev(self):
        dev = {'tai10_10.txt': [7, 8, 3, 9, 2], 'tai15_15.txt': [7, 0, 8, 4, 5], 'tai20_20.txt': [6, 0, 3, 8, 2],
               'tai4_4.txt': [0, 7, 5, 8, 6], 'tai5_5.txt': [3, 0, 9, 8, 1], 'tai7_7.txt': [3, 0, 8, 2, 1]}

        return dev






# Task configuration for benchmark task
ENTRY_NAME = 'solve'
FUNCTION_SIGNATURE = 'def solve(...):'
IMPORT_HEADER = 'import numpy as np\nimport scipy.optimize as opt\nimport math\nimport random\nfrom typing import List, Tuple, Dict'
TASK_DESCRIPTION = '("The Open Shop Scheduling Problem involves scheduling a set of jobs across a set of machines with "'
OBJECTIVE_TEXT = 'You are optimizing the implementation of `solve` for the LLM4AD task.\\n\\nTask description:\\n("The Open Shop Scheduling Problem involves scheduling a set of jobs across a set of machines with "\\n\\nYour goal is to return a correct and efficient function whose score (computed by the task evaluator) is as high as possible.'
TEMPLATE_FUNCTION = 'import numpy as np\nimport scipy.optimize as opt\nimport math\nimport random\nfrom typing import List, Tuple, Dict\ndef solve(n_jobs: int, n_machines: int, times: list, machines: list) -> dict:\n    """\n    Solves a single open shop scheduling test case.\n    Input kwargs:\n        - n_jobs (int): Number of jobs.\n        - n_machines (int): Number of machines (and operations per job).\n        - times (list of list of int): A 2D list of processing times for each operation.\n          Dimensions: n_jobs x n_machines.\n        - machines (list of list of int): A 2D list specifying the machine assignment for each operation.\n          Dimensions: n_jobs x n_machines. Note machine is 1-indexed.\n    Output:\n        solution (dict): A dictionary containing:\n            - start_times (list of list of int): A 2D list of start times for each operation.\n              Dimensions: n_jobs x n_machines.\n            Each start time must be a non-negative integer, and the schedule must respect the following constraint:\n                (i) Non-parallel operation: Each job must be processed on only one machine at a time\n                (ii) Machine exclusivity: For operations assigned to the same machine, their processing intervals must not overlap.\n            The evaluation function will use the start_times to compute the makespan and verify the constraints.\n    """\n\n    # Extract the case parameters\n    n_jobs = kwargs["n_jobs"]\n    n_machines = kwargs["n_machines"]\n    times = kwargs["times"]\n    machines = kwargs["machines"]\n\n    # TODO: Implement the scheduling algorithm here.\n    # For now, we provide a dummy solution where all operations start at time 0.\n\n    # Create a start_times list with dimensions n_jobs x n_machines, initializing all start times to 0.\n    start_times = [[0 for _ in range(n_machines)] for _ in range(n_jobs)]\n\n    # Build the solution dictionary.\n    solution = {"start_times": start_times}\n\n    return solution'
EVAL_CLASS_NAME = 'OSSEvaluationCB'
EVAL_KWARGS = {'timeout_seconds': 60}

def build_trace_problem(**override_eval_kwargs) -> dict:
    """Build a Trace-ready problem using embedded benchmark evaluator."""
    
    # Create evaluator instance with embedded class
    eval_kwargs_final = EVAL_KWARGS.copy()
    eval_kwargs_final.update(override_eval_kwargs)
    
    evaluator = globals()[EVAL_CLASS_NAME](**eval_kwargs_final)
    
    from llm4ad_loader import AutonomousEvaluatorGuide
    from opto import trace
    
    # Create parameter
    initial_code = TEMPLATE_FUNCTION.strip()
    param = trace.node(initial_code, name='__code', 
                      description=f'The code should start with: {FUNCTION_SIGNATURE}', 
                      trainable=True)
    
    # Create guide using benchmark embedded evaluator
    guide = AutonomousEvaluatorGuide(evaluator, ENTRY_NAME, IMPORT_HEADER, 
                                   timeout=eval_kwargs_final.get('timeout_seconds', 30))
    
    # Create dataset
    train_dataset = dict(
        inputs=[TASK_DESCRIPTION],
        infos=[{'imports': IMPORT_HEADER, 'entry': ENTRY_NAME}]
    )
    
    # Optimizer kwargs
    optimizer_kwargs = dict(
        objective=OBJECTIVE_TEXT,
        memory_size=10
    )
    
    return dict(
        param=param,
        guide=guide,
        train_dataset=train_dataset,
        optimizer_kwargs=optimizer_kwargs,
        metadata=dict(
            entry=ENTRY_NAME,
            function_signature=FUNCTION_SIGNATURE,
            eval_class=EVAL_CLASS_NAME,
            benchmark=True,
        )
    )
